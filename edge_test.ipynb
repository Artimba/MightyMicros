{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This notebook was me playing around with edge detectors to see if they would work for this problem. Didn't really work that well.\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abaf1e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_canny(image):\n",
    "    gray_frame = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    return cv2.Canny(gray_frame, 100, 200)\n",
    "\n",
    "def apply_sobel(image):\n",
    "    gray_frame = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    sobel_x = cv2.Sobel(gray_frame, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobel_y = cv2.Sobel(gray_frame, cv2.CV_64F, 0, 1, ksize=3)\n",
    "\n",
    "    abs_sobel_x = cv2.convertScaleAbs(sobel_x)\n",
    "    abs_sobel_y = cv2.convertScaleAbs(sobel_y)\n",
    "\n",
    "    combined_sobel = cv2.addWeighted(abs_sobel_x, 0.5, abs_sobel_y, 0.5, 0)\n",
    "    return combined_sobel\n",
    "\n",
    "def apply_scharr(image):\n",
    "    gray_frame = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    scharr_x = cv2.Scharr(gray_frame, cv2.CV_64F, 1, 0)\n",
    "    scharr_y = cv2.Scharr(gray_frame, cv2.CV_64F, 0, 1)\n",
    "\n",
    "    abs_scharr_x = cv2.convertScaleAbs(scharr_x)\n",
    "    abs_scharr_y = cv2.convertScaleAbs(scharr_y)\n",
    "\n",
    "    combined_scharr = cv2.addWeighted(abs_scharr_x, 0.5, abs_scharr_y, 0.5, 0)\n",
    "    return combined_scharr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de02083d",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"data/20231017_120545.mp4\"\n",
    "\n",
    "video = cv2.VideoCapture(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "228854dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "status, frame = video.read()\n",
    "# cv2.imshow(\"Original\", frame)\n",
    "if status:\n",
    "    canny = apply_canny(frame)\n",
    "    cv2.imshow(\"Canny Result\", canny)\n",
    "    cv2.imwrite(\"canny.jpg\", canny)\n",
    "    \n",
    "    sobel = apply_sobel(frame)\n",
    "    # cv2.imshow(\"Sobel Result\", sobel)\n",
    "    \n",
    "    scharr = apply_scharr(frame)\n",
    "    # cv2.imshow(\"Scharr Result\", scharr)\n",
    "\n",
    "# while True:\n",
    "#     status, frame = video.read()\n",
    "    \n",
    "#     if status:\n",
    "#         canny = apply_canny(frame)\n",
    "#         sobel = apply_sobel(frame)\n",
    "#         scharr = apply_scharr(frame)\n",
    "    \n",
    "#     cv2.imshow(\"Canny Result\", canny) # Complete loss during microtome movement\n",
    "#     cv2.imshow(\"Sobel Result\", sobel) # Noisy\n",
    "#     cv2.imshow(\"Scharr Result\", scharr) # Noisy\n",
    "    \n",
    "#     key = cv2.waitKey(40)\n",
    "#     if key & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4c21eca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_points = []\n",
    "selecting_roi = False\n",
    "\n",
    "# Mouse callback function to give a bit of a helping hand for where to look for slices.\n",
    "def select_roi(event, x, y, flags, param):\n",
    "    global roi_points, selecting_roi\n",
    "\n",
    "    # Left mouse button down\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        roi_points = [(x, y)]\n",
    "        selecting_roi = True\n",
    "\n",
    "    # Left mouse button up\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        roi_points.append((x, y))\n",
    "        selecting_roi = False\n",
    "\n",
    "        # Draw rectangle on the image for visualization\n",
    "        cv2.rectangle(img, roi_points[0], roi_points[1], (255,0,0), 2)\n",
    "        cv2.imshow('Image', img)\n",
    "\n",
    "# Load the image\n",
    "img = cv2.imread('canny.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "cv2.imshow('Image', img)\n",
    "\n",
    "# Set mouse callback\n",
    "cv2.setMouseCallback('Image', select_roi)\n",
    "\n",
    "# Wait for a key press and then process the ROI\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Extract and process the ROI after selecting\n",
    "if len(roi_points) == 2:\n",
    "    roi = img[roi_points[0][1]:roi_points[1][1], roi_points[0][0]:roi_points[1][0]]\n",
    "    \n",
    "    # Binary thresholding\n",
    "    _, roi = cv2.threshold(roi, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Apply morphological operations to attempt to close gaps\n",
    "    kernel = np.ones((7,7), np.uint8)  # Adjust kernel for gap closing\n",
    "    closing = cv2.morphologyEx(roi, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "\n",
    "    # Find contours in the image\n",
    "    contours, _ = cv2.findContours(closing, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Draw bounding boxes around detected trapezoids / contours\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) > 100:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            cv2.rectangle(roi, (x, y), (x + w, y + h), (255, 255, 255), 2)\n",
    "\n",
    "    # Display the processed ROI\n",
    "    cv2.imshow('Processed ROI', roi)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14afc89e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mighty",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
